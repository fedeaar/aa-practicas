## 4.3. Consideremos $K$-fold cross validation con las siguientes modificaciones: Para cada instancia $x_i$ dentro de un conjunto de datos $D$ se tiene un mapeo $G$ que le asigna un único grupo $g \in G$ tal que $G(x_i) = g$ (pueden pensarlo como un `DICC(INSTANCIA, GRUPO)`). Al dividir $D$ en los $k$ folds, se asegura que cada grupo $g$ este contenido únicamente en un fold.

### a) Construir el algoritmo `GROUP_K_CROSS_VAL(A: ALGORITMO, HS: HYPERS, D: DATA, M: MÉTRICA, G: GRUPOS, K: INT): FLOAT` que devuelve el resultado de evaluar el algoritmo dado con los hiperparámetros dados y algún valor de $k$ respetando los grupos dados.

Por como está armada la aridad de la función, podemos pensar la división en folds como la división del conjunto de grupos en folds (ie. un grupo se considera como una instancia). Luego, el algoritmo es practicamente igual al de `K-CROSS-VAL`, realizando la división en folds por grupo.

### b) ¿En que escenarios podría tener sentido utilizar este procedimiento? Desarrolle.

Podría tener sentido si existe una dependencia entre distintas instancias del dataset. Por ejemplo, que hayan sido generadas por una misma fuente (pensar en recortes de audio, por ejemplo, donde más de un recorte puede provenir de la misma persona).

Si utilizamos cross validation común, instancias de una misma fuente pueden terminar tanto en el set de entrenamiento como en el de validación (en diversos folds), lo que podría resultar en una evaluación 'sobre-optimista' del poder de generalización del modelo, ya que la información de validación se habría filtrado en el entrenamiento (volviendo al ejemplo, probablemente sea más fácil predecir voces que son 'similares' a las usadas durante el entrenamiento). 


### c) ¿Qué cambiaría en su implementación si hubiese más folds que grupos?

Se podría limitar tal que $k \leq |G|$, al igual que el `K-CROSS-VAL` limita $k \leq n$ con $n$ la cantidad de instancias. 

Si no, se debería alterar conceptualmente el algoritmo, lo que es debatible. Podríamos, por ejemplo:
1. armar más folds, donde algunos grupos aparezcan distribuidos entre ellos. 
2. no hacer el cruce: $k - 1$ folds de train contra $1$ de validación, sino $k - l$ de train contra $l$ de validación, donde $l$ está determinado de forma que ambos sets queden disjuntos en terminos de los grupos que contienen. 

Sin embargo, esto le agrega mucha complejidad al algoritmo, en especial dado que el objetivo del mismo es aprovechar al maximo los datos disponibles en entrenamiento.
