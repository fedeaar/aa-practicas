## 5.8. ¿Binaria o 2 clases? 

### Sean $A$ y $B$ clasificadores que distinguen entre imágenes de perros e imágenes de gatos. Al medir la performance del clasificador (utilizando $F_1$ para evitar los problemas de utilizar accuracy) y “gato” como clase positiva, obtenemos $F_1(A) = 0.9$, $F_1(B) = 0.8$. ¿Podemos concluir que el clasificador $A$ es mejor que el clasificador $B$ para este problema? Resolver los siguientes ítems para poder responder a la pregunta:

No lo podemos concluir.

### a) Al calcular $F_1$ utilizando “gato” como clase positiva, ¿importa qué ocurre con los perros que fueron clasificados correctamente? Revisar la Tercera Parte del [notebook_metricas.ipynb](./notebook_06_metricas-published.ipynb) y decidir cuál clasificador funciona mejor, basándose en las métricas obtenidas. Observar el cambio que ocurre al intercambiar cuál es la clase positiva.

No importa, ya que esas clasificaciones corresponden con TN en la clase 'gato' y, por ende, no influyen en su score $F_1$. En el notebook, el clasificador $B$ parece funcionar mejor, ya que tiene mejores scores para ambas clases 'en conjunto'.

### b) ¿Para qué sirve el parámetro average en la función `f1_score` de la librería sklearn?

En problemas multiclase, define como agregar los resultados obtenidos al medir cada clase, por turno, como 'positiva'.

### c) ¿Qué sucede si la cantidad de instancias sobre las que fueron testeados es distinta? ¿Cómo se ve afectada la métrica $F_1$ al cambiar los True Negatives? Correr la Cuarta Parte del [notebook_metricas.ipynb](./notebook_06_metricas-published.ipynb). El gráfico muestra cómo varía la métrica $F_1$ al aumentar la cantidad de True Negatives (observar que estamos cambiando la cantidad de instancias sobre las que testeamos). ¿Qué se puede concluir de este experimento?

Si la cantidad de instancias de testeo varia y las clases están desbalanceadas, es posible que la métrica no capture correctamente el comportamiento de un modelo sobre instancias de la clase minoritaria. $F_1$ es invariante a cambios en la cantidad de TN. 

Del experimento del notebook podemos concluir que, para problemas binarios donde no hay una clase 'positiva' y otra 'negativa', no sirve utilizar $F_1$. Hay que, al menos, agregar los scores de $F_1$ u otra métrica para ambas clases, donde cada una se considera 'positiva' por turno. Esto se extiende también a problemas multiclase.

