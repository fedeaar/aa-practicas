## 5.9. 

### Recordemos la métrica de accuracy para un problema de clasificación, para simplificar solo consideraremos el caso binario, sea $y$ el vector de etiquetas verdadera, $\hat{y}$ las respectivas predicciones, y $N$ la cantidad total de muestras ($y, \hat{y} \in \{0, 1\}^N$): 

### $$ accuracy(y, \hat{y}) = \frac{1}{N}\sum_{i=1}^N 1(\hat{y}^{(i)} = y^{(i)})$$ 

### Donde $1(x)$ es la función indicadora (vale 1 si el argumento es verdadero, 0 caso contrario). Vamos a introducir una pequeña modificación en como contamos los aciertos para cada clase, supongamos que $p$ es la proporción de la clase minoritaria (positiva): 

### $$balanced\_accuracy(y, \hat{y}) = \frac{1}{N}(\frac{1}{2p} \sum_{i=1}^N 1(\hat{y}^{(i)} = y^{(i)} = 1) + \frac{1}{2(1 − p)} \sum_{i=1}^N 1(\hat{y}^{(i)} = y^{(i)} = 0))$$

### a) ¿Qué rango de valores posibles tiene esta métrica? ¿Cuánto vale esta métrica si tenemos un clasificador constante que predice siempre la clase mayoritaria $\hat{y} = 0$? ¿Y si predice siempre la clase minoritaria?

Dado que es una suma de valores positivos, su valor es mayor o igual a $0$. 

Dado que la suma de las sumatorias está acotada por $N$, sigue que
$$ 
\begin{split}
0 \leq balanced\_accuracy(y, \hat{y}) 
    &\leq \frac{1}{N}(\frac{1}{2p}\sigma_1 + \frac{1}{2(1 − p)}\sigma_2)\\
    &= \frac{1}{N}\cdot\frac{2(1 - p)\cdot \sigma_1 + 2p\cdot \sigma_2}{2p \cdot 2(1 - p)}\\
    &= \frac{1}{N}\cdot\frac{\sigma_1  + p (\sigma_2 - \sigma_1)}{2p \cdot (1 - p)}\\
    &= \frac{1}{N}\cdot\frac{k + \frac{k}{N} (N - k - k)}{2 \frac{k}{N} \cdot (1 - \frac{k}{N})}\\
    &= \frac{1}{N}\cdot\frac{\frac{2Nk - 2k^2}{N}}{2 \frac{k}{N} \cdot (1 - \frac{k}{N})}\\
    &= \frac{1}{N}\cdot\frac{2\frac{k}{N}(N - k)}{2 \frac{k}{N} \cdot (1 - \frac{k}{N})}\\
    &= \frac{1}{N}\cdot\frac{N - k}{1 - \frac{k}{N}}\\
    &= \frac{1}{N}\cdot\frac{N - k}{\frac{N - k}{N}}\\
    &= 1
\end{split}
$$

donde $\sigma_1$ y $\sigma_2$ corresponden a una clasificación perfecta, tal que $\sigma_1 + \sigma_2 = N$ y si definimos $\sigma_1 := k$, sigue que $\sigma_2 = N - k$ y $p = \frac{k}{N}$.

Si se predice siempre la clase mayoritaria, la fórmula se reduce a
$$
\begin{split}
    \frac{1}{N}\frac{1}{2(1 − p)} \sum_{i=1}^N 1(\hat{y}^{(i)} = y^{(i)} = 0)
    \leq \frac{1}{2(N − k)} (N - k) = \frac{1}{2}
\end{split}
$$
derivando los valores de la sumatoria para el caso de clasificación perfecta y $p$, al igual que antes.

Si se predice siempre la clase minoritaria, la fórmula se reduce a
$$
\begin{split}
    \frac{1}{N}\frac{1}{2p} \sum_{i=1}^N 1(\hat{y}^{(i)} = y^{(i)} = 1)
    \leq \frac{1}{2 k} k = \frac{1}{2}
\end{split}
$$
derivando los valores de la sumatoria para el caso de clasificación perfecta y $p$, al igual que antes.



### b) Escribir `balanced_accuracy` en términos de TP, FP, TN y FN.

Tomando la clase mayoritaria como la clase positiva

$$
\begin{split}
    balanced\_accuracy(y, \hat{y}) 
        &= \frac{1}{N}(\frac{1}{2p} \sum_{i=1}^N 1(\hat{y}^{(i)} = y^{(i)} = 1) + \frac{1}{2(1 − p)} \sum_{i=1}^N 1(\hat{y}^{(i)} = y^{(i)} = 0))\\
        &= \frac{1}{TN + TP + FN + FP}(\frac{1}{2\frac{TN + FP}{TN + TP + FN + FP}} TN + \frac{1}{2(1 − \frac{TN + FP}{TN + TP + FN + FP})} TP)\\
        &= \frac{TN}{2(TN + FP)} + \frac{TP}{2(TP + FN)}\\
        &= \frac{1}{2}(\frac{TN}{TN + FP} + \frac{TP}{TP + FN})\\
        
\end{split}
$$


### c) Mostrar que en el caso binario, esta métrica es equivalente al promedio aritmético entre sensitividad (true positive rate) y la especificidad (true negative rate).

El resultado de la parte (b) es, por definición el promedio aritmético entre senisitividad y especificidad.
