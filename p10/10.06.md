
## 10.6. Pensando al error cuadrático medio (MSE) como una función de pérdida: $$MSE_{X,y} = \frac{1}{n} \sum_{i=1}^n (\hat{h}(x^{(i)}) − y^{(i)})$$ Verdadero o Falso:

### a) Esta métrica se define de esta manera para regresión lineal, para otros métodos (tal como árboles de regresión) hay que redefinir la fórmula anterior.

Falso. La expresión específica del modelo se contempla en $\hat{h}(x^{(i)})$.

### b) La función, vista como una función de pérdida, es siempre convexa.

Falso, depende de la elección de $\hat{h}(x^{(i)})$. Ej. en redes neuronales, generalmente no es convexa.

### c) Los siguientes, siempre en el contexto de regresión lineal con pesos $w$:

#### I) Se puede usar como función de pérdida viéndola como una función de $X$ e $y$ (los datos).

Falso. La función de pérdida es en términos de $w$.

#### II) Se puede usar como función de pérdida viéndola como una función de $w$.

Verdadero.

#### III) La función, vista como una función de pérdida, es siempre convexa.

Verdadero.

#### IV) Se busca minimizar esta función para $X$ e $y$ fijos en cada iteración de descenso de gradiente.

Verdadero.

#### V) En mini-batch gradient descent, en cada batch se minimiza una función de pérdida distinta.

Falso. La función de pérdida es la misma, pero cambia $w$.
