## 8.7. Verdadero o Falso (justificar)

### a) En Bagging, cada subconjunto tiene la misma cantidad de instancias que el dataset original.

Falso. Cada subconjunto tiene una muestra acotada de la cantidad de instancias, que puede contar con repetidos.

### b) En RF, cada subconjunto tiene la misma cantidad de instancias que el dataset original.

Falso. RF suele tener en cada subconjunto 2/3 de los datos.

### c) En RF, cada árbol es entrenado sólo con un subconjunto de los atributos.

Falso. Se toma un subconjunto (posiblemente) diferente en cada nodo.

### d) En Random Forest, tomar m = 1 significa que cada árbol tendría a lo sumo un nivel.

Falso. En tanto el paper mencionado en el ej. 2, $m$ refiere a la cantidad de atributos a considerar al evaluar el mejor corte en cada nodo de cada árbol.

### e) En Random Forest, tomar m = 1 significa que cada árbol tendría a lo sumo un atributo en todo el árbol.

Falso. Significa que se elige aleatoriamente $1$ solo atributo a considerar al evaluar el mejor corte en cada nodo de cada árbol.

### f) En Random Forest, la importancia de atributos puede medirse como la suma (entre todos los árboles) de la ganancia obtenida en cada corte por cada atributo

Falso. En tanto el paper, se mide estimando la diferencia en error out of bag al anular un atributo por medio de una permutación de sus valores contra el error out of bag al considerar todos los atributos. 

### g) En Random Forest, la importancia de atributos puede medirse como la suma (entre todos los árboles) de la ganancia obtenida en cada corte por cada atributo dividido B.

Falso. Ver (f).

### h) La varianza que se reduce utilizando Bagging debería ser mayor que la que se reduce utilizando Random Forest.

Falso. Random Forests está diseñado para mejorar los resultados de Bagging. No tengo muy claro igual, si necesariamente RF va a ser mejor, creo que no.

### i) En Bagging, se puede estimar el error de generalización sólo utilizando un train set (sin necesidad de utilizar CrossVal) y los resultados seguramente estén sub-estimando el error real.

Falso. Por un lado, el error se estima con una técnica similar a cross validation ---out of bag error--- para la cual sería engañoso decir que 'solo hay un train set', al menos en comparación a cross validation. Los resultados, según el paper, bagging (out of bag) sobreestima el error real.

### j) En Bagging, se puede estimar el error de generalización sólo utilizando un train set (sin necesidad de utilizar CrossVal) y los resultados seguramente estén sobre-estimando el error real.

Falso. Ver (i).
